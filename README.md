<div align='center'>

# ğŸ† NLP Project : ìˆ˜ëŠ¥ ë¬¸ì œ í’€ì´ AI ëª¨ë¸ ìƒì„±

</div>

## âœï¸ ëŒ€íšŒ ì†Œê°œ

|    íŠ¹ì§•     | ì„¤ëª…                                                                                                                         |
| :---------: | ---------------------------------------------------------------------------------------------------------------------------- |
|  ëŒ€íšŒ ì£¼ì œ  | ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ìº í”„ AI-Tech 8ê¸° NLP íŠ¸ë™ì˜ Generation for NLP ëŒ€íšŒ<br/>                                                        |
|  ëŒ€íšŒ ì„¤ëª…  | í•œêµ­ì–´ì˜ íŠ¹ì„±ê³¼ ìˆ˜ëŠ¥ ì‹œí—˜ì˜ íŠ¹ì§•ì„ ë°”íƒ•ìœ¼ë¡œ ìˆ˜ëŠ¥ì— íŠ¹í™”ëœ AI ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” í”„ë¡œì íŠ¸                                        |
|  ì§„í–‰ ê¸°ê°„  | 2025ë…„ 12ì›” 17ì¼ ~ 2026ë…„ 1ì›” 6ì¼ (3ì£¼)                                                                                      |
| ë°ì´í„° êµ¬ì„± | í•™ìŠµë°ì´í„° ì…‹: KMMLU / MMMLU(Ko) / KLUE MRC ì¤‘ 2031ê°œ</br>í‰ê°€ë°ì´í„° ì…‹: ìˆ˜ëŠ¥í˜• ë¬¸ì œ + KMMLU / MMMLU(Ko) / KLUE MRC ì´ 869ê°œ |
|  í‰ê°€ ì§€í‘œ  | Macro F1-score = (ê° í´ë˜ìŠ¤ë³„ F1-scoreì˜ í•©) / í´ë˜ìŠ¤ ìˆ˜                                                                     |
|  ë©ì—… ë¦¬í¬íŠ¸ | [Gen for NLP NLP-03 ë©ì—… ë¦¬í¬íŠ¸](https://github.com/boostcampaitech8/pro-nlp-generationfornlp-nlp-03/blob/main/assets/Gen%20for%20NLP_NLP-03.pdf) |


## ğŸ–ï¸ Leader Board

### Public Leader Board (4ìœ„)

<img width="1216" alt="image" src="./assets/public_rank.png">

### ğŸ¥ˆ Priavate Leader Board (2ìœ„)

<img width="1216" alt="image" src="./assets/private_rank.png">

## ğŸ‘¨â€ğŸ’» Contributors

<table align='center'>
  <tr>
    </td>
        <td align="center">
      <img src="https://github.com/choijunho-AIDeveloper.png" alt="ìµœì¤€í˜¸" width="100" height="100" style="border-radius: 50%;"/><br>
      <a href="https://github.com/choijunho-AIDeveloper">
        <img src="https://img.shields.io/badge/ìµœì¤€í˜¸-grey?style=for-the-badge&logo=github" alt="badge ìµœì¤€í˜¸"/>
      </a>
    </td>
    <td align="center">
      <img src="https://github.com/kyunhui.png" alt="ê¹€ìœ¤í¬" width="100" height="100" style="border-radius: 50%;"/><br>
      <a href="https://github.com/kyunhui">
        <img src="https://img.shields.io/badge/ê¹€ìœ¤í¬-grey?style=for-the-badge&logo=github" alt="badge ê¹€ìœ¤í¬"/>
      </a>
    </td>
    <td align="center">
      <img src="https://github.com/Parkseojin2001.png" alt="ë°•ì„œì§„" width="100" height="100" style="border-radius: 50%;"/><br>
      <a href="https://github.com/Parkseojin2001">
        <img src="https://img.shields.io/badge/ë°•ì„œì§„-grey?style=for-the-badge&logo=github" alt="badge ë°•ì„œì§„"/>
      </a>
    </td>
    <td align="center">
      <img src="https://github.com/shihtzu-918.png" alt="ê³½ë‚˜ì˜" width="100" height="100" style="border-radius: 50%;"/><br>
      <a href="https://github.com/shihtzu-918">
        <img src="https://img.shields.io/badge/ê³½ë‚˜ì˜-grey?style=for-the-badge&logo=github" alt="badge ê³½ë‚˜ì˜"/>
      </a>
    </td>
    <td align="center">
      <img src="https://github.com/2sseul.png" alt="ê¹€ì´ìŠ¬" width="100" height="100" style="border-radius: 50%;"/><br>
      <a href="https://github.com/2sseul">
        <img src="https://img.shields.io/badge/ê¹€ì´ìŠ¬-grey?style=for-the-badge&logo=github" alt="badge ê¹€ì´ìŠ¬"/>
      </a>
    </td>
    <td align="center">
      <img src="https://github.com/hyejinw.png" alt="ìš°í˜œì§„" width="100" height="100" style="border-radius: 50%;"/><br>
      <a href="https://github.com/hyejinw">
        <img src="https://img.shields.io/badge/ìš°í˜œì§„-grey?style=for-the-badge&logo=github" alt="badge ìš°í˜œì§„"/>
      </a>
  </tr>
</table>

## ğŸ‘¼ ì—­í•  ë¶„ë‹´

| ì´ë¦„   | ì—­í•                                                                                                          |
| ------ | ------------------------------------------------------------------------------------------------------------ |
| ìµœì¤€í˜¸ | Agentic RAG êµ¬ì„± ë° ì ìš©, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, RAG ë°ì´í„° êµ¬ì„±                                               |
| ê¹€ìœ¤í¬ | ë°ì´í„° EDA ë° ì¦ê°•, Unsloth ê¸°ë°˜ ëª¨ë¸ë§, gguf í¬ë§· ê¸°ë°˜ Few-Shot inference, Agentic RAG êµ¬ì„± ë° ì ìš©         |
| ë°•ì„œì§„ | Baseline Code ë¶„ì„, Unsloth ê¸°ë°˜ ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ ë¶„ì„, CoT í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, RAGì™€ ì¶”ë¡ ëª¨ë¸ í†µí•©        |
| ê³½ë‚˜ì˜ | Baseline Code ë¶„ì„ ë° ì½”ë“œ ëª¨ë“ˆí™”, ë°ì´í„° ìˆ˜ì§‘ ë° ì¦ê°•, í•™ìŠµ ë°ì´í„° ì„ë² ë”© ë¶„ì„, Unsloth ê¸°ë°˜ ëª¨ë¸ë§, ì•™ìƒë¸” |
| ê¹€ì´ìŠ¬ | Baseline Code ë¶„ì„, streamlit ì‹œê°í™”, ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ ë¶„ì„, RAG êµ¬í˜„ ë° ì„±ëŠ¥í‰ê°€, Agentic RAG êµ¬ì„± ë° ì ìš© |
| ìš°í˜œì§„ | ë°ì´í„° EDA ë° ì¦ê°•, Few-Shot í”„ë¡¬í”„íŒ…, gguf inference, ì•™ìƒë¸”                                                |

## âœğŸ» í”„ë¡œì íŠ¸ ê°œìš”

ë³¸ í”„ë¡œì íŠ¸ëŠ” ìˆ˜ëŠ¥í˜• ê°ê´€ì‹ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê°œë°œëœ ì•™ìƒë¸” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. Qwen ëª¨ë¸ê³¼ Agentic RAG, GGUF ê¸°ë°˜ ì¶”ë¡ ì„ ê²°í•©í•˜ì—¬ ê³ í’ˆì§ˆì˜ ë‹µë³€ ìƒì„±ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- **Agentic RAG System**: LangGraph ê¸°ë°˜ ë‹¤ë‹¨ê³„ ê²€ìƒ‰ ë° ì¶”ë¡  íŒŒì´í”„ë¼ì¸

  - Subject Finder: ë¬¸ì œ ì£¼ì œ ìë™ ë¶„ë¥˜
  - Query Generator: ë‹¤ì¤‘ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
  - FAISS Vector Store: BGE-M3 ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰
  - Score & Refine: ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í‰ê°€ ë° ì¬ê²€ìƒ‰
  - Few-shot Learning: ìœ ì‚¬ ë¬¸ì œ ì˜ˆì‹œ í™œìš©

- **Qwen Fine-tuning**: Unsloth ê¸°ë°˜ íš¨ìœ¨ì ì¸ LoRA í•™ìŠµ

  - DoRA + RSLoRA ì ìš©
  - Gradient Checkpointing
  - 4-bit Quantization ì§€ì›

- **GGUF Inference**: llama.cpp ê¸°ë°˜ ê²½ëŸ‰ ì¶”ë¡ 

  - Qwen3-Next-80B-A3B-Thinking ëª¨ë¸ ì‚¬ìš©
  - Few-shot í”„ë¡¬í”„íŒ…
  - ë‹¤ì¤‘ ì‹œë“œ ì•™ìƒë¸”

- **Ensemble Strategy**: ë‹¤ì¤‘ ëª¨ë¸ ê²°ê³¼ íˆ¬í‘œ ë°©ì‹ ê²°í•©

### ğŸ“ƒ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

<img width="1000" alt="image" src="./assets/system_architecture.png">

## ğŸ“ í´ë” êµ¬ì¡°

```
pro-nlp-generationfornlp-nlp-03-main/
â”œâ”€â”€ config/                    # ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ rag/                       # Agentic RAG ëª¨ë“ˆ
â”‚   â”œâ”€â”€ agent.py              # LangGraph ì—ì´ì „íŠ¸ êµ¬í˜„
â”‚   â”œâ”€â”€ chunker.py            # ë¬¸ì„œ ì²­í‚¹
â”‚   â”œâ”€â”€ upload_to_faiss.py    # FAISS ë²¡í„° DB êµ¬ì¶•
â”‚   â”œâ”€â”€ upload_to_chroma.py   # ChromaDB êµ¬ì¶•
â”‚   â”œâ”€â”€ upload_to_pinecone.py # Pinecone ì—…ë¡œë“œ
â”‚   â”œâ”€â”€ prompt/               # RAG í”„ë¡¬í”„íŠ¸
â”‚   â”œâ”€â”€ data/                 # RAG ë°ì´í„°
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ gguf/                      # GGUF ì¶”ë¡  ëª¨ë“ˆ
â”‚   â””â”€â”€ inference_fewshot.py  # Few-shot ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ datacollator/              # ë°ì´í„° ì „ì²˜ë¦¬ ë° í•™ìŠµ
â”‚   â”œâ”€â”€ train.py              # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ train_no_datacollator.py
â”‚   â”œâ”€â”€ train_resume.py       # ì²´í¬í¬ì¸íŠ¸ ì¬ê°œ
â”‚   â”œâ”€â”€ inference.py          # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ inference_prod.py     # í”„ë¡œë•ì…˜ ì¶”ë¡ 
â”‚   â”œâ”€â”€ data_utils.py         # ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ prompt_utils.py       # í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
â”‚   â”œâ”€â”€ config.py             # í•™ìŠµ ì„¤ì •
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ src/                       # í•µì‹¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ model.py              # ëª¨ë¸ ë˜í¼
â”‚   â”œâ”€â”€ dataset.py            # ë°ì´í„°ì…‹ ì²˜ë¦¬
â”‚   â”œâ”€â”€ utils.py              # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â””â”€â”€ prompt_template.py    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”œâ”€â”€ main.py                    # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ assets/                    # ë¦¬ì†ŒìŠ¤ íŒŒì¼
```

## ğŸ’» ì„¤ì¹˜

### ê¸°ë³¸ í™˜ê²½

```bash
pip install -r datacollator/requirements.txt
pip install -r rag/requirements.txt
```

### RAGìš© FAISS ì„¤ì¹˜

```bash
pip install faiss-gpu  # GPU ì‚¬ìš© ì‹œ
# ë˜ëŠ”
pip install faiss-cpu  # CPU ì‚¬ìš© ì‹œ
```

### GGUF ì¶”ë¡ ìš© llama.cpp ì„¤ì¹˜

```bash
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
make LLAMA_CUDA=1  # GPU ì‚¬ìš© ì‹œ
# ë˜ëŠ”
make  # CPU ì‚¬ìš© ì‹œ
```

## ì‚¬ìš©ë²•

### 1. Agentic RAG íŒŒì´í”„ë¼ì¸

#### 1.1 ë¬¸ì„œ ë²¡í„°í™”

```bash
cd rag
python upload_to_faiss.py
```

#### 1.2 RAG ì¶”ë¡  ì‹¤í–‰

```bash
python agent.py
```

**ì£¼ìš” ì„¤ì •**:

- `model_id`: Qwen2.5-32B-Instruct-bnb-4bit
- `max_seq_length`: 8192
- `temperature`: 0.1
- `topk`: 3 (ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜)
- `threshold`: 0.65 (ì¬ê²€ìƒ‰ ì„ê³„ê°’)

#### 1.3 Agent ì›Œí¬í”Œë¡œìš°

1. **Subject Finder**: ë¬¸ì œ ì£¼ì œ ë¶„ë¥˜ (í•œêµ­ì‚¬, ê²½ì œ, ì² í•™, ê³¼í•™ê¸°ìˆ , ì‚¬íšŒê³¼í•™, ì¸ë¬¸í•™, ë¬¸í•™)
2. **Query Generator**: ë‹¤ì¤‘ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
3. **Retrieval**: FAISSì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
4. **Score Retrieval**: ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í‰ê°€ (ìœ ì‚¬ë„ 0.7 + validity 0.3)
5. **Refine Search**: ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ì¿¼ë¦¬ ê°œì„  í›„ ì¬ê²€ìƒ‰ (ìµœëŒ€ 3íšŒ)
6. **Generate**: ìµœì¢… ë‹µë³€ ìƒì„±

### 2. Qwen ëª¨ë¸ í•™ìŠµ

#### 2.1 ê¸°ë³¸ í•™ìŠµ

```bash
python main.py --config ./config/config.yaml --task train
```

#### 2.2 ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ

```bash
cd datacollator
python train_resume.py
```

#### 2.3 í•™ìŠµ ì„¤ì • (config.yaml)

```yaml
model:
  experiment_name: "Qwen2.5-32B-Instruct-bnb-4bit"
  train:
    model_name: "unsloth/Qwen2.5-32B-Instruct-bnb-4bit"

peft:
  r: 64
  lora_alpha: 32
  use_dora: True
  use_rslora: True

UnslothTrainingArguments:
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 16
  num_train_epochs: 3
  learning_rate: 5e-5
  lr_scheduler_type: "cosine"
  optim: "adamw_8bit"
```

### 3. GGUF Few-shot ì¶”ë¡ 

#### 3.1 llama-server ì‹¤í–‰ (ë³„ë„ í„°ë¯¸ë„)

```bash
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
./llama.cpp/build/bin/llama-server \
  -m ./models/Qwen3-Next-80B-A3B-Thinking-UD-Q3_K_XL.gguf \
  -c 32768 \
  -np 2 \
  -cb \
  -fa on \
  --port 8000 \
  --host 0.0.0.0
```

#### 3.2 ì¶”ë¡  ì‹¤í–‰

```bash
cd gguf
python inference_fewshot.py
```

**ì£¼ìš” ì„¤ì •**:

- `CTX_SIZE`: 32768 (Context window)
- `MAX_TOKENS`: 6000 (ì¶œë ¥ ìµœëŒ€ í† í°)
- `NUM_LOOPS`: 2 (ì•™ìƒë¸”ìš© ë°˜ë³µ íšŸìˆ˜)
- `temperature`: 1.0
- Few-shot ì˜ˆì‹œ 3ê°œ ìë™ ì‚½ì…

### 4. ëª¨ë¸ ì¶”ë¡ 

#### 4.1 í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ë¡ 

```bash
python main.py --config ./config/config.yaml --task test
```

#### 4.2 ê²€ì¦ ë°ì´í„° ì¶”ë¡ 

```bash
python main.py --config ./config/config.yaml --task test --valid True
```

#### 4.3 ì¶”ë¡  ëª¨ë“œ ì„ íƒ

```bash
# Logit ê¸°ë°˜ ì¶”ë¡  (ê¸°ë³¸)
python main.py --task test --mode logit

# Generate ê¸°ë°˜ ì¶”ë¡ 
python main.py --task test --mode generate
```

## ëª¨ë¸

- **Reader (RAG)**: unsloth/Qwen2.5-32B-Instruct-bnb-4bit
- **Reader (Fine-tuned)**: Qwen2.5-32B-Instruct + LoRA
- **GGUF**: Qwen3-Next-80B-A3B-Thinking-UD-Q3_K_XL
- **Embedding**: BAAI/bge-m3
- **Vector Store**: FAISS (ì£¼ì œë³„ 7ê°œ DB)

## ì°¸ê³ ìë£Œ

- [Unsloth](https://github.com/unslothai/unsloth) - íš¨ìœ¨ì ì¸ LLM Fine-tuning
- [LangGraph](https://github.com/langchain-ai/langgraph) - Agent ì›Œí¬í”Œë¡œìš° í”„ë ˆì„ì›Œí¬
- [llama.cpp](https://github.com/ggerganov/llama.cpp) - GGUF ì¶”ë¡  ì—”ì§„
- [BGE-M3](https://huggingface.co/BAAI/bge-m3) - ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸
- [Qwen](https://github.com/QwenLM/Qwen) - Alibaba ì˜¤í”ˆì†ŒìŠ¤ LLM
