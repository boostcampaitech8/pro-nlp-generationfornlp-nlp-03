{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316dc459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jjunh\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Exception in thread Thread-4 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jjunh\\anaconda3\\envs\\langchain\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\jjunh\\anaconda3\\envs\\langchain\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\jjunh\\anaconda3\\envs\\langchain\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc0 in position 6: invalid start byte\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:12<00:00,  4.11s/it]\n",
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "import re\n",
    "\n",
    "\n",
    "model_id = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.1,\n",
    "    do_sample=False,\n",
    "    device_map=\"auto\",\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5695ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"북쪽 구지에서 이상한 소리로 부르는 것이 있었다.…(중략) … 구간(九干)들은 이 말을 따라 모두 기뻐하면서 노래하고 춤을 추었다. 자줏빛줄이 하늘에서 드리워져서 땅에 닿았다. 그 줄이 내려온 곳을 따라가 붉은 보자기에 싸인 금으로 만든 상자를 발견하고 열어보니, 해처럼 둥근 황금알 여섯 개가 있었다. 알여섯이 모두 변하여 어린 아이가 되었다.…(중략) … 가장 큰 알에서 태어난 수로(首露)가 왕위에 올라(가)를/ 을 세웠다.－삼국유사－\"\n",
    "question = \"(가) 나라에 대한 설명으로 옳은 것은?\"\n",
    "choices = ['해상교역을 통해 우수한 철을 수출하였다.', '박, 석, 김씨가 교대로 왕위를 계승하였다.', '경당을 설치하여 학문과 무예를 가르쳤다.', '정사암회의를 통해 재상을 선발하였다.']\n",
    "answer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d44d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    paragraph : str\n",
    "    question: str\n",
    "    choices: list\n",
    "    subject: str\n",
    "    queries: list[str]\n",
    "    retrieval: list[str]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc38e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe62b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af6a2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_query = \"\"\"\n",
    "아래 지문과 문제를 보고 과목을 분류하세요.\n",
    "지문: {paragraph}\n",
    "문제: {question}\n",
    "선택지: {choices}\n",
    "\n",
    "과목 후보: 철학, 한국사, 심리, 문학\n",
    "\n",
    "답변 (과목명만):\"\"\"\n",
    "\n",
    "def subject_finder(state: AgentState) -> AgentState:\n",
    "    messages = PromptTemplate.from_template(subject_query)\n",
    "    chain = messages | llm | StrOutputParser()\n",
    "    ai_message = chain.invoke({\"paragraph\": state[\"paragraph\"],\n",
    "                                \"question\": state[\"question\"],\n",
    "                                \"choices\": state[\"choices\"]})\n",
    "    subject = ai_message.strip().split()[0] if ai_message.strip() else \"\"\n",
    "    return {\"subject\": subject}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d1b3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis_query = \"\"\"\n",
    "# 당신은 검색 최적화 전문가입니다. 주어진 문제를 분석하여 정답을 찾기 위해 필요한 구체적인 파생 질문들을 생성합니다.\n",
    "\n",
    "# 과목: {subject}\n",
    "# 지문: {paragraph}\n",
    "# 질문: {question}\n",
    "# 선택지: {choices}\n",
    "# ###SEARCH_START###와 ###SEARCH_END### 사이에만 파생 질문들을 파이썬 리스트 형식으로 작성하세요.\n",
    "\n",
    "# 다음 규칙을 따르세요.\n",
    "# - 위 과목의 지문을 참고하여 선택지 중 질문에 가장 적합한 답변을 만들기 위해 다음의 순서로 짧은 파생 질문을 파이썬 리스트 형식으로 생성하세요.\n",
    "# - 질문과 관련된 지문의 핵심 키워드를 질문과 연관지은 검색어을 생성하세요.\n",
    "# - 각 선택지를 질문과 연관지은 검색어만을 생성하세요.\n",
    "# - 파생 질문은 간결하고 구체적이어야 합니다. 다른 설명이나 부연은 절대 포함하지 마세요.\n",
    "# ###SEARCH_START###\"\"\"\n",
    "\n",
    "hypothesis_query = \"\"\"당신은 검색 전문가입니다. 아래의 한국사 문제를 해결하기 위해, 검색 엔진에 입력할 '질문 리스트'를 파이썬 리스트 형식으로 생성하십시오.\n",
    "\n",
    "### 생성 규칙:\n",
    "1. **첫 번째 요소**: 질문과 관련된 지문의 핵심 키워드를 질문과 연관지은 질문을 생성하세요.\n",
    "2. **나머지 요소**: 각 선택지를 질문과 연관지은 질문을 생성하세요.\n",
    "3. **금지 사항**: \"지문의 핵심 키워드\", \"선택지 1\" 같은 서술어는 절대 포함하지 마십시오. 오직 파이썬 리스트만 출력하십시오.\n",
    "4. **질문 형식**: \"~는 무엇인가?\", \"~의 특징은?\"과 같은 완전한 의문문 형태로 작성하십시오.\n",
    "5. **생성 규칙**: '질문 리스트' 생성이 끝나면 종료하세요. 추가적인 출력을 하지마세요.\n",
    "\n",
    "### 출력 예시:\n",
    "[\"질문 1\", \"질문 2\", \"질문 3\", ...]\n",
    "\n",
    "과목: {subject}\n",
    "지문: {paragraph}\n",
    "질문: {question}\n",
    "선택지: {choices}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# HyDE, Step-back Prompting\n",
    "def mid_hypothesis(state: AgentState) -> AgentState:\n",
    "    messages = PromptTemplate.from_template(hypothesis_query)\n",
    "    chain = messages | llm | StrOutputParser()\n",
    "    ai_message = chain.invoke({\"paragraph\": state[\"paragraph\"],\n",
    "                                \"question\": state[\"question\"],\n",
    "                                \"choices\": state[\"choices\"],\n",
    "                                \"subject\": state[\"subject\"]})\n",
    "    print(ai_message)\n",
    "    pattern = r\"###SEARCH_START###(.*?)###SEARCH_END###\"\n",
    "    match = re.search(pattern, ai_message, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        content = match.group(1).strip()\n",
    "        queries = [line.strip(\"- \").strip() for line in content.split(\"\\n\") if line.strip()]\n",
    "    else:\n",
    "        queries = [state[\"question\"]] \n",
    "\n",
    "    return {\"queries\": queries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "331e965f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9fc71ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0656aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d9e9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_korea_history_json(file_path):\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    for item in data:\n",
    "        title = item.get('title', '')\n",
    "        sub_title = item.get('sub_title', '')\n",
    "        url = item.get('url', '')\n",
    "        content_list = item.get('content', [])\n",
    "        \n",
    "        for content in content_list:\n",
    "            section_title = content.get('section_title', '')\n",
    "            section_text = content.get('section_text', '')\n",
    "            \n",
    "            doc = Document(\n",
    "                page_content=section_text,\n",
    "                metadata={\n",
    "                    'title': title,\n",
    "                    'sub_title': sub_title,\n",
    "                    'section_title': section_title,\n",
    "                    'url': url\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75c31d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\". \", \" \"],\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "\n",
    "documents = load_korea_history_json(\"./data/korea_history.json\")\n",
    "\n",
    "document_list = []\n",
    "for doc in documents:\n",
    "    if len(doc.page_content) <= 100:\n",
    "        document_list.append(doc)\n",
    "    else:\n",
    "        splits = text_splitter.split_documents([doc])\n",
    "        document_list.extend(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142684d",
   "metadata": {},
   "source": [
    "### 최초 1회만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784efb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_chroma import Chroma\n",
    "\n",
    "# database = Chroma.from_documents(documents=document_list, embedding=embeddings, persist_directory=\"./chroma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a2d7f",
   "metadata": {},
   "source": [
    "### 이후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d76874fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "database = Chroma(persist_directory=\"./chroma\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "483d3092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(state: AgentState):\n",
    "    queries = state['queries']\n",
    "    \n",
    "    results = []\n",
    "    for query in queries:\n",
    "        docs = database.similarity_search(query, k=1)\n",
    "        if docs:\n",
    "            results.append(docs[0].page_content)\n",
    "        else:\n",
    "            results.append(\"검색 결과 없음\")\n",
    "            \n",
    "    return {\"retrieval\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7588cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_query = \"\"\"\n",
    "당신은 {subject} 과목 문제 풀이 전문가입니다. 지문, 질문, 참고자료를 바탕으로 선택지 중 가장 적합한 답변을 생성하세요.\n",
    "지문: {paragraph}\n",
    "질문: {question}\n",
    "참고자료: {reference}\n",
    "선택지: {choices}\n",
    "\n",
    "답변은 선택지 중 하나만 생성하세요. 다른 설명은 절대 하지 마세요.\n",
    "\n",
    "답변(선택지 중 하나만 답변):\"\"\"\n",
    "\n",
    "def generate(state: AgentState) -> AgentState:\n",
    "    messages = PromptTemplate.from_template(generate_query)\n",
    "    chain = messages | llm | StrOutputParser()\n",
    "    \n",
    "    queries = state[\"queries\"]\n",
    "    retrieval = state[\"retrieval\"]\n",
    "\n",
    "    reference = \"\"\n",
    "    for query, retrieve in zip(queries, retrieval):\n",
    "        template = f\"{query}에 대한 참고자료: {retrieve}\"\n",
    "        reference += template + \"\\n\"\n",
    "\n",
    "    answer = chain.invoke({\"paragraph\": state[\"paragraph\"],\n",
    "                            \"question\": state[\"question\"],\n",
    "                            \"choices\": state[\"choices\"],\n",
    "                            \"subject\": state[\"subject\"],\n",
    "                            \"reference\": reference})\n",
    "    answer = answer.strip().split('\\n')[0].strip()\n",
    "    return {\"answer\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "456f5ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2118cc30c90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_node('subject_finder', subject_finder)\n",
    "graph_builder.add_node('mid_hypothesis', mid_hypothesis)\n",
    "graph_builder.add_node('retrieval', retrieval)\n",
    "graph_builder.add_node('generate', generate)\n",
    "\n",
    "graph_builder.add_edge(START, 'subject_finder')\n",
    "graph_builder.add_edge('subject_finder', 'mid_hypothesis')\n",
    "graph_builder.add_edge('mid_hypothesis','retrieval')\n",
    "graph_builder.add_edge('retrieval', 'generate')\n",
    "graph_builder.add_edge('generate', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfd2e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5f08af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, Image\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "add0dd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'do_sample': True}. If this is not desired, please set these values explicitly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 질문 리스트 생성\n",
      "[\"북쪽 구지에서 이상한 소리로 부르는 것이 있었다는 문장에서 나타나는 주제는 무엇인가?\", \"해처럼 둥근 황금알 여섯 개가 있었다는 문장에서 나타나는 주제는 무엇인가?\", \"황금알이 모두 변하여 어린 아이가 되었다는 문장에서 나타나는 주제는 무엇인가?\", \"가장 큰 알에서 태어난 수로가 왕위에 올라 세웠다는 문장에서 나타나는 주제는 무엇인가?\", \"정사암회의를 통해 재상을 선발하였다는 문장에서 나타나는 주제는 무엇인가?\", \"해상교역을 통해 우수한 철을 수출하였다는 문장에서 나타나는 주제는 무엇인가?\", \"박, 석, 김씨가 교대로 왕위를 계승하였다는 문장에서 나타나는 주제는 무엇인가?\", \"경당을 설치하여 학문과 무예를 가르쳤다라는 문장에서 나타나는 주제는 무엇인가?\"]\n",
      "\n",
      "[질문 리스트 생성 완료]\n",
      "\n",
      "[\"북쪽 구지에서 이상한 소리로 부르는 것이 있었다는 문장에서 나타나는 주제는 무엇인가?\", \"해처럼 둥근 황금알 여섯 개가 있었다는 문장에서 나타나는 주제는 무엇인가?\", \"황금알이 모두 변하여 어린 아이가 되었다는 문장에서 나타나는 주제는 무엇인가?\", \"가장 큰 알에서 태어난 수로가 왕위에 올라 세웠다는 문장에서 나타나는 주제는 무엇인가?\", \"정사암회의를 통해 재상을 선발하였다는 문장에서 나타나는 주제는 무엇인가?\", \"해상교역을 통해 우수한 철을 수출하였다는 문장에서 나타나는 주제는 무엇인가?\", \"박, 석, 김씨가 교대로 왕위를 계승하였다는 문장에서 나타나는 주제는 무엇인가?\", \"경당을 설치하여 학문과 무예를 가르쳤다라는 문장에서 나타나는 주제는 무엇인가?\"]\n",
      "\n",
      "\n",
      "```python\n",
      "[\n",
      "    \"북쪽 구\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'paragraph': '북쪽 구지에서 이상한 소리로 부르는 것이 있었다.…(중략) … 구간(九干)들은 이 말을 따라 모두 기뻐하면서 노래하고 춤을 추었다. 자줏빛줄이 하늘에서 드리워져서 땅에 닿았다. 그 줄이 내려온 곳을 따라가 붉은 보자기에 싸인 금으로 만든 상자를 발견하고 열어보니, 해처럼 둥근 황금알 여섯 개가 있었다. 알여섯이 모두 변하여 어린 아이가 되었다.…(중략) … 가장 큰 알에서 태어난 수로(首露)가 왕위에 올라(가)를/ 을 세웠다.－삼국유사－',\n",
       " 'question': '(가) 나라에 대한 설명으로 옳은 것은?',\n",
       " 'choices': ['해상교역을 통해 우수한 철을 수출하였다.',\n",
       "  '박, 석, 김씨가 교대로 왕위를 계승하였다.',\n",
       "  '경당을 설치하여 학문과 무예를 가르쳤다.',\n",
       "  '정사암회의를 통해 재상을 선발하였다.'],\n",
       " 'subject': '한국사',\n",
       " 'queries': ['(가) 나라에 대한 설명으로 옳은 것은?'],\n",
       " 'retrieval': ['. 우선 단편적인 기록을 통해 살펴보자면 다음과 같다.국가가 존재하려면 필요한 요소가 있다. 바로 땅과 백성, 그리고 나라를 운영할 체제이다'],\n",
       " 'answer': \"'박, 석, 김씨가 교대로 왕위를 계승하였다.'\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {'paragraph': paragraph, 'question': question, 'choices': choices}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49c6032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea242a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
