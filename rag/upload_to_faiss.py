import pickle
import os
import json
import torch
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document
from tqdm import tqdm

# 1. BGE-M3 ë¡œì»¬ ëª¨ë¸ ì„¤ì • (V100 GPU í™œìš©)
print("--- ë¡œì»¬ BGE-M3 ëª¨ë¸ì„ GPU(CUDA)ì— ë¡œë“œ ì¤‘... ---")
model_name = "BAAI/bge-m3"
embeddings_model = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs={'device': 'cuda'}, 
    encode_kwargs={'normalize_embeddings': True}
)

def get_subject_from_path(file_path: str) -> str:
    """íŒŒì¼ ê²½ë¡œ ë˜ëŠ” íŒŒì¼ëª…ì— ë”°ë¥¸ ì£¼ì œ ë§¤í•‘"""
    path = file_path.lower()
    if 'history' in path: return "korean-history"
    elif 'economy' in path: return "economics"
    elif 'philosophy' in path: return "philosophy"
    elif 'science' in path: return "science-tech"
    elif 'social' in path: return "social-science"
    elif 'human' in path or 'humanity' in path: return "humanities"
    elif 'literature' in path: return "literature"
    else: return "etc"

def upload_all_to_faiss_gpu(
    file_key_json: str = "data/file_key2.json",
    base_persist_directory: str = "./FAISS/faiss_db"
):
    # JSON íŒŒì¼ ë¡œë“œ
    if not os.path.exists(file_key_json):
        print(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_key_json}")
        return

    with open(file_key_json, 'r', encoding='utf-8') as f:
        file_map = json.load(f)

    if not os.path.exists(base_persist_directory):
        os.makedirs(base_persist_directory)

    for source_json, pkl_file in file_map.items():
        # íŒŒì¼ëª…ì„ ì¶”ì¶œí•´ì„œ ID ìƒì„±ì— ì‚¬ìš© (ì˜ˆ: economy_01_chunks)
        file_tag = os.path.basename(pkl_file).replace(".pkl", "")
        
        subject = get_subject_from_path(source_json)
        subject_path = os.path.join(base_persist_directory, subject)
        
        if not os.path.exists(pkl_file):
            print(f"âš ï¸ PKL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pkl_file}, ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        print(f"\n[{subject}] ì²˜ë¦¬ ì¤‘: {pkl_file}")
        
        # 2. Chunks ë¡œë“œ
        with open(pkl_file, 'rb') as f:
            chunks = pickle.load(f)

        # 3. ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ í™•ì¸
        if os.path.exists(os.path.join(subject_path, "index.faiss")):
            vector_db = FAISS.load_local(subject_path, embeddings_model, allow_dangerous_deserialization=True)
            print(f"ê¸°ì¡´ {subject} ì¸ë±ìŠ¤ì— ë°ì´í„°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.")
        else:
            vector_db = None
            print(f"ìƒˆë¡œìš´ {subject} ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

        # 4. Document ê°ì²´ ìƒì„± (Preprocessing)
        docs = []
        ids = []
        for chunk in tqdm(chunks, desc=f"Preprocessing {subject}", leave=False):
            text = chunk['text'][:6000] 
            doc = Document(
                page_content=text,
                metadata={
                    'subject': subject,
                    'file': file_tag,
                    'title': chunk.get('title', ''),
                    'doc_id': chunk.get('doc_id', 0),
                    'chunk_id': chunk.get('chunk_id', 0)
                }
            )
            docs.append(doc)
            
            # [í•µì‹¬ ìˆ˜ì •] IDì— file_tagë¥¼ ì¶”ê°€í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
            unique_id = f"{file_tag}_{chunk.get('doc_id', 0)}_{chunk.get('chunk_id', 0)}"
            ids.append(unique_id)

        # 5. FAISS ì—…ë¡œë“œ (GPU ì—°ì‚° ê³¼ì •ì„ tqdmìœ¼ë¡œ ì‹œê°í™”)
        batch_size = 1000
        with tqdm(total=len(docs), desc=f"ğŸš€ Embedding {subject} (GPU)") as pbar:
            for i in range(0, len(docs), batch_size):
                batch_docs = docs[i : i + batch_size]
                batch_ids = ids[i : i + batch_size]
                
                if vector_db is None:
                    vector_db = FAISS.from_documents(batch_docs, embeddings_model, ids=batch_ids)
                else:
                    vector_db.add_documents(batch_docs, ids=batch_ids)
                
                pbar.update(len(batch_docs))

        # 6. ìµœì¢… ì €ì¥
        if vector_db:
            vector_db.save_local(subject_path)
            print(f"âœ… {subject} ì €ì¥ ì™„ë£Œ: {subject_path}")

if __name__ == "__main__":
    upload_all_to_faiss_gpu()